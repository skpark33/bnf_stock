import requests
import pandas as pd
from datetime import datetime, timedelta
import time
from pykrx import stock
import json
import os
import warnings
import argparse
import sys
warnings.filterwarnings('ignore')


class KISAPIClient:
    """í•œêµ­íˆ¬ìì¦ê¶Œ API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, app_key, app_secret, account_no, mock=False):
        self.app_key = app_key
        self.app_secret = app_secret
        self.account_no = account_no

        if mock:
            self.base_url = "https://openapivts.koreainvestment.com:29443"
            print("ğŸ”§ ëª¨ì˜íˆ¬ì ëª¨ë“œ")
        else:
            self.base_url = "https://openapi.koreainvestment.com:9443"
            print("ğŸ’° ì‹¤ì „íˆ¬ì ëª¨ë“œ")

        self.access_token = None

        if not app_key or not app_secret or not account_no:
            raise ValueError("APP_KEY, APP_SECRET, ACCOUNT_NOëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")

        print(f"APP_KEY: {app_key[:10]}..." if len(app_key) > 10 else f"APP_KEY: {app_key}")
        print(f"Base URL: {self.base_url}")

        print("ğŸ“Š KOSPI 200 ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“œ (pykrx ì‚¬ìš©)")

    def get_kospi200_stocks(self, use_cache=True, cache_file="kospi_200_code.json"):
        """KOSPI 200 ì¢…ëª© ì½”ë“œ ì¡°íšŒ (ìºì‹± ì§€ì›)"""
        if use_cache and os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    print(f"âœ“ ìºì‹œ íŒŒì¼ì—ì„œ KOSPI 200 ì¢…ëª© {len(cached_data['stocks'])}ê°œ ë¡œë“œ ì™„ë£Œ")
                    print(f"  ìºì‹œ ìƒì„±ì¼: {cached_data['created_at']}")
                    return cached_data['stocks']
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                print("  ìƒˆë¡œ ì¢…ëª© ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")

        try:
            stock_codes = stock.get_index_portfolio_deposit_file("1028")

            stocks = []
            for code in stock_codes:
                name = stock.get_market_ticker_name(code)
                stocks.append({
                    'code': code,
                    'name': name
                })

            print(f"âœ“ KOSPI 200 ì¢…ëª© {len(stocks)}ê°œ ë¡œë“œ ì™„ë£Œ")

            if use_cache:
                try:
                    cache_data = {
                        'created_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        'stocks': stocks
                    }
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(cache_data, f, ensure_ascii=False, indent=2)
                    print(f"âœ“ ì¢…ëª© ì½”ë“œë¥¼ '{cache_file}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    print(f"âš ï¸ ìºì‹œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

            return stocks
        except Exception as e:
            print(f"âŒ KOSPI 200 ì¢…ëª© ì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_historical_data_pykrx(self, stock_code, target_date):
        """pykrxë¥¼ ì´ìš©í•œ íŠ¹ì •ì¼ ë°ì´í„° ì¡°íšŒ"""
        try:
            df = stock.get_market_ohlcv(target_date, target_date, stock_code)
            if df.empty:
                return None
            return df
        except Exception as e:
            return None


class DataCollector:
    """KOSPI 200 ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""

    def __init__(self, api_client):
        self.api = api_client

    def get_output_file_path(self, year):
        """ì—°ë„ë³„ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return f"data/json/kospi200/{year}/kospi200_data.json"

    def is_trading_day(self, target_date):
        """ê±°ë˜ì¼ì¸ì§€ í™•ì¸"""
        try:
            # KOSPI ì§€ìˆ˜ë¡œ ê±°ë˜ì¼ í™•ì¸
            df = stock.get_index_ohlcv(target_date, target_date, "1001")
            return not df.empty
        except:
            return False

    def collect_data_for_date(self, stock_codes, target_date):
        """íŠ¹ì • ë‚ ì§œì˜ KOSPI 200 ì „ì²´ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘"""
        date_str = target_date
        date_obj = datetime.strptime(target_date, "%Y%m%d")
        
        print(f"\n{'='*60}")
        print(f"ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ë‚ ì§œ: {date_obj.strftime('%Y-%m-%d')} ({date_obj.strftime('%A')})")
        print(f"{'='*60}")

        # ê±°ë˜ì¼ í™•ì¸
        if not self.is_trading_day(target_date):
            print(f"âš ï¸  {target_date}ëŠ” íœ´ì¥ì¼ì…ë‹ˆë‹¤.")
            return {
                'date': target_date,
                'is_holiday': True,
                'stocks': []
            }

        print(f"âœ“ ê±°ë˜ì¼ í™•ì¸ ì™„ë£Œ")
        
        results = []
        total = len(stock_codes)

        print(f"ğŸ“Š ì´ {total}ê°œ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        print("-" * 60)

        for idx, stock_info in enumerate(stock_codes, 1):
            try:
                if idx % 50 == 0:
                    print(f"ì§„í–‰ì¤‘: {idx}/{total} ({idx/total*100:.1f}%)")

                stock_code = stock_info['code']
                stock_name = stock_info['name']

                # API í˜¸ì¶œ ê°„ê²© (ê³¼ë¶€í•˜ ë°©ì§€)
                time.sleep(0.05)

                df = self.api.get_historical_data_pykrx(stock_code, target_date)
                
                if df is None or df.empty:
                    continue

                # ë°ì´í„° ì¶”ì¶œ
                row = df.iloc[0]
                
                result = {
                    'code': stock_code,
                    'name': stock_name,
                    'open': int(row['ì‹œê°€']),
                    'high': int(row['ê³ ê°€']),
                    'low': int(row['ì €ê°€']),
                    'close': int(row['ì¢…ê°€']),
                    'volume': int(row['ê±°ë˜ëŸ‰']),
                    'value': int(row['ê±°ë˜ëŒ€ê¸ˆ']) if 'ê±°ë˜ëŒ€ê¸ˆ' in row else 0
                }
                
                results.append(result)

            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ì¢…ëª©ì€ ê±´ë„ˆë›°ê¸°
                continue

        print(f"\nâœ“ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}/{total}ê°œ ì¢…ëª©")

        return {
            'date': target_date,
            'is_holiday': False,
            'stocks': results
        }

    def save_results_by_year(self, all_data):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ì—°ë„ë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™”
            data_by_year = {}
            for day_data in all_data:
                year = day_data['date'][:4]  # YYYYMMDDì—ì„œ YYYY ì¶”ì¶œ
                if year not in data_by_year:
                    data_by_year[year] = []
                data_by_year[year].append(day_data)

            # ì—°ë„ë³„ë¡œ íŒŒì¼ ì €ì¥
            for year, year_data in data_by_year.items():
                output_file = self.get_output_file_path(year)
                os.makedirs(os.path.dirname(output_file), exist_ok=True)

                output = {
                    'year': year,
                    'generated_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'total_days': len(year_data),
                    'data': year_data
                }

                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(output, f, ensure_ascii=False, indent=2)

                trading_days = sum(1 for d in year_data if not d['is_holiday'])
                holidays = len(year_data) - trading_days
                
                print(f"\n{'='*60}")
                print(f"âœ“ JSON ì €ì¥ ì™„ë£Œ: {output_file}")
                print(f"  {year}ë…„: ì´ {len(year_data)}ì¼ (ê±°ë˜ì¼: {trading_days}ì¼, íœ´ì¥ì¼: {holidays}ì¼)")
                print(f"{'='*60}")

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def load_existing_data_by_year(year):
    """íŠ¹ì • ì—°ë„ì˜ ê¸°ì¡´ JSON íŒŒì¼ ë¡œë“œ"""
    output_file = f"data/json/kospi200/{year}/kospi200_data.json"
    if not os.path.exists(output_file):
        return None
    
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ {year}ë…„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def get_all_years_from_directory():
    """ì €ì¥ëœ ëª¨ë“  ì—°ë„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    base_dir = "data/json/kospi200"
    if not os.path.exists(base_dir):
        return []
    
    years = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path) and item.isdigit() and len(item) == 4:
            years.append(item)
    
    return sorted(years)


def get_last_date_from_all_data():
    """ëª¨ë“  ì—°ë„ ë°ì´í„°ì—ì„œ ë§ˆì§€ë§‰ ë‚ ì§œ ì¶”ì¶œ"""
    years = get_all_years_from_directory()
    if not years:
        return None
    
    # ê°€ì¥ ìµœê·¼ ì—°ë„ë¶€í„° ì—­ìˆœìœ¼ë¡œ í™•ì¸
    for year in reversed(years):
        data = load_existing_data_by_year(year)
        if data and 'data' in data and data['data']:
            dates = [d['date'] for d in data['data']]
            dates.sort()
            return dates[-1]
    
    return None


def merge_data_by_year(new_data):
    """ì‹ ê·œ ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©"""
    # ì—°ë„ë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™”
    data_by_year = {}
    for day_data in new_data:
        year = day_data['date'][:4]
        if year not in data_by_year:
            data_by_year[year] = []
        data_by_year[year].append(day_data)

    # ê° ì—°ë„ë³„ë¡œ ë³‘í•©
    for year, year_new_data in data_by_year.items():
        output_file = f"data/json/kospi200/{year}/kospi200_data.json"
        existing_data = load_existing_data_by_year(year)
        
        if existing_data:
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³‘í•©
            existing_dates = {d['date'] for d in existing_data['data']}
            
            # ì¤‘ë³µë˜ì§€ ì•Šì€ ì‹ ê·œ ë°ì´í„°ë§Œ ì¶”ê°€
            for new_entry in year_new_data:
                if new_entry['date'] not in existing_dates:
                    existing_data['data'].append(new_entry)
            
            # ë‚ ì§œìˆœ ì •ë ¬
            existing_data['data'].sort(key=lambda x: x['date'])
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            existing_data['generated_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            existing_data['total_days'] = len(existing_data['data'])
        else:
            # ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            existing_data = {
                'year': year,
                'generated_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'total_days': len(year_new_data),
                'data': sorted(year_new_data, key=lambda x: x['date'])
            }
        
        # ì €ì¥
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        
        trading_days = sum(1 for d in existing_data['data'] if not d['is_holiday'])
        holidays = existing_data['total_days'] - trading_days
        
        print(f"\n{'='*60}")
        print(f"âœ“ ë°ì´í„° ë³‘í•© ì™„ë£Œ: {output_file}")
        print(f"  {year}ë…„: ì´ {existing_data['total_days']}ì¼ (ê±°ë˜ì¼: {trading_days}ì¼, íœ´ì¥ì¼: {holidays}ì¼)")
        print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(
        description='KOSPI 200 ì¢…ëª© ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œê·¸ë¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ì‚¬ìš© ì˜ˆì‹œ:
  1. íŠ¹ì • ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘:
     python get_data.py --config config.json --from 20250101 --to 20250131

  2. íŠ¹ì •ì¼ ë°ì´í„° ìˆ˜ì§‘:
     python get_data.py --config config.json --from 20250115

  3. ëˆ„ë½ëœ ë°ì´í„° ì¶”ê°€ (ë§ˆì§€ë§‰ ë‚ ì§œ ë‹¤ìŒë‚ ë¶€í„° ì–´ì œê¹Œì§€):
     python get_data.py --config config.json --add

ì¶œë ¥:
  - data/json/kospi200/[ì—°ë„]/kospi200_data.json (ì—°ë„ë³„ë¡œ íŒŒì¼ ë¶„ë¦¬)
  - íœ´ì¥ì¼ì€ dateì™€ is_holiday: trueë¡œ í‘œì‹œë¨
        '''
    )

    parser.add_argument('--config', required=True, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)')
    parser.add_argument('--from', dest='from_date', help='ì‹œì‘ì¼ (YYYYMMDD)')
    parser.add_argument('--to', dest='to_date', help='ì¢…ë£Œì¼ (YYYYMMDD)')
    parser.add_argument('--add', action='store_true', 
                       help='ê¸°ì¡´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œ ë‹¤ìŒë‚ ë¶€í„° ì–´ì œê¹Œì§€ ë°ì´í„° ì¶”ê°€')

    args = parser.parse_args()

    print("=" * 60)
    print("KOSPI 200 ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œê·¸ë¨")
    print("=" * 60)

    # --add ì˜µì…˜ ì²˜ë¦¬
    if args.add:
        print("\nğŸ“Œ --add ì˜µì…˜: ëˆ„ë½ëœ ë°ì´í„° ì¶”ê°€ ëª¨ë“œ")
        
        last_date = get_last_date_from_all_data()
        if not last_date:
            print(f"âŒ ê¸°ì¡´ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("   --from ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒë¶€í„° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            sys.exit(1)
        
        print(f"âœ“ ê¸°ì¡´ ë°ì´í„° ë§ˆì§€ë§‰ ë‚ ì§œ: {last_date}")
        
        # ë§ˆì§€ë§‰ ë‚ ì§œ ë‹¤ìŒë‚ ë¶€í„° ì–´ì œê¹Œì§€
        start_date = (datetime.strptime(last_date, "%Y%m%d") + timedelta(days=1)).strftime("%Y%m%d")
        end_date = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
        
        if start_date > end_date:
            print(f"âœ“ ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ ë‚ ì§œê°€ ìµœì‹ ì…ë‹ˆë‹¤)")
            sys.exit(0)
        
        print(f"ğŸ“… ì¶”ê°€ ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
        
        args.from_date = start_date
        args.to_date = end_date

    # ë‚ ì§œ ë²”ìœ„ ì²˜ë¦¬
    if not args.from_date:
        print("âŒ --from ì˜µì…˜ ë˜ëŠ” --add ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("\nì‚¬ìš© ì˜ˆì‹œ:")
        print("  python get_data.py --config config.json --from 20250101 --to 20250131")
        print("  python get_data.py --config config.json --add")
        sys.exit(1)

    try:
        start = datetime.strptime(args.from_date, "%Y%m%d")
        end = datetime.strptime(args.to_date, "%Y%m%d") if args.to_date else start

        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime("%Y%m%d"))
            current += timedelta(days=1)

        print(f"\nğŸ“… ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {args.from_date} ~ {end.strftime('%Y%m%d')}")
        print(f"   ì´ {len(date_list)}ì¼ ì²˜ë¦¬ ì˜ˆì •\n")

    except ValueError:
        print("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYYYMMDD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    try:
        with open(args.config, 'r', encoding='utf-8') as f:
            config = json.load(f)

        app_key = config.get('app_key')
        app_secret = config.get('app_secret')
        account = config.get('account')
        mock = config.get('mock', False)

        print(f"âœ“ ì„¤ì • íŒŒì¼ '{args.config}' ë¡œë“œ ì™„ë£Œ\n")

    except FileNotFoundError:
        print(f"âŒ ì„¤ì • íŒŒì¼ '{args.config}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"âŒ ì„¤ì • íŒŒì¼ '{args.config}'ì˜ JSON í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” pykrxë§Œ ì‚¬ìš©í•˜ì§€ë§Œ config í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    try:
        api = KISAPIClient(
            app_key,
            app_secret,
            account,
            mock=mock
        )
    except Exception as e:
        print(f"\nâŒ API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # ì¢…ëª© ì½”ë“œ ë¡œë”©
    print("=" * 60)
    print("KOSPI 200 ì¢…ëª© ì½”ë“œ ë¡œë”© ì¤‘...")
    print("=" * 60)

    kospi200_stocks = api.get_kospi200_stocks(use_cache=True)
    
    if not kospi200_stocks:
        print("âŒ ì¢…ëª© ì½”ë“œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    print(f"âœ“ ì´ {len(kospi200_stocks)}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ\n")

    # ë°ì´í„° ìˆ˜ì§‘
    collector = DataCollector(api)
    all_data = []

    for target_date in date_list:
        date_data = collector.collect_data_for_date(kospi200_stocks, target_date)
        all_data.append(date_data)
        time.sleep(0.5)  # ë‚ ì§œ ê°„ ëŒ€ê¸°

    # ê²°ê³¼ ì €ì¥ (--add ì˜µì…˜ì¸ ê²½ìš° ë³‘í•©, ì•„ë‹ˆë©´ ìƒˆë¡œ ì €ì¥)
    if args.add:
        merge_data_by_year(all_data)
    else:
        collector.save_results_by_year(all_data)

    print("\nâœ… ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()

